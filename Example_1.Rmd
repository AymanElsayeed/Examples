---
title: "Classification"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load("class")
```
## Read CSV
```{r}
df <- read.csv("~/Desktop/Examples/ccdefault.csv", header = T)
```
## Normalize Data

If ranges for variables are very different, then it's a
good idea to normalize the variables, which puts them in
similar ranges. Use custom function for now.

## Define function for normalizing data
```{r}
normalize <- function(x) {
  norm <- ((x - min(x))/(max(x) - min(x)))
  return (norm)
}
```



### Apply function to data frame (but not index or outcome)
```{r}
dfn <- as.data.frame(lapply(df[, 2:24], normalize))
head(dfn)
```

### Put outcome variable back on and rename
```{r}
dfn <- cbind(dfn, df[, 25])
names(dfn)[24] <- "DEFAULT"
```

### Check data
```{r}
colnames(dfn)
head(dfn)
```

## Split Data
#### Split data into training set (2/3) and testing set (1/3)
```{r}
set.seed(2786)  # Random seed
dfn.split <- sample(2, nrow(dfn), 
                     replace = TRUE,
                     prob = c(2/3, 1/3))
```

Create training and testing datasets without outcome
labels. Use just the first 23 variables.
```{r}
dfn.train <- dfn[dfn.split == 1, 1:23]
dfn.test  <- dfn[dfn.split == 2, 1:23]
```


# Create outcome labels
```{r}
dfn.train.labels <- dfn[dfn.split == 1, 24]
dfn.test.labels  <- dfn[dfn.split == 2, 24]
```

### Build and test Classifier 

Build classifier for test data.

k = number of neighbors to compare; odd n avoids ties.

Try with several values of k and check accuracy on

following table.
```{r}
dfn.pred <- knn(train = dfn.train,
                test = dfn.test, 
                cl = dfn.train.labels,  # true class
                k = 9)                  # n neighbors
```



### Compare predicted outcome to observed outcome
```{r}
table(dfn.pred, dfn.test.labels)
```








Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
